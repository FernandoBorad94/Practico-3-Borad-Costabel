{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCU - Proyecto Webscraping\n",
    "Proyecto para la Licenciatura en Datos y Negocios de la Universidad Católica del Uruguay"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Importamos la librería requests para hacer las solicitudes HTTP\n",
    "Importamos la librería BeautifulSoup para analizar el HTML de la página"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T23:11:16.038711Z",
     "start_time": "2025-09-22T23:11:16.032291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inicialización de parámetros y estructura de resultados"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ciudades_objetivo = [\"Montevideo\", \"Maldonado\", \"Canelones\"]\n",
    "\n",
    "# Inicializar resultados\n",
    "resultado = {ciudad: [] for ciudad in ciudades_objetivo}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aqui hacemos la paginación hasta completar 10 propiedades por ciudad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "page = 1\n",
    "# Seguimos hasta que cada ciudad tenga 10 propiedades\n",
    "while any(len(resultado[ciudad]) < 10 for ciudad in ciudades_objetivo):\n",
    "    url = f\"https://www.infocasas.com.uy/alquiler/casas-y-apartamentos/uruguay/pagina-{page}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Realizamos la extracción de campos por página"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "    # Ubicaciones\n",
    "    location = soup.find_all('strong', class_='lc-location body body-1 body-bold medium')\n",
    "    # Precios\n",
    "    price = soup.find_all('p', class_='main-price')\n",
    "    # Links\n",
    "    links = soup.find_all('a', class_='lc-data', href=True)\n",
    "\n",
    "    if not location or not price or not links:  # si ya no hay más propiedades\n",
    "        break"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aqui realizamos la  extracción por propiedad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "    # Iterar por todas las propiedades de la página\n",
    "    for loc, p, link_tag in zip(location, price, links):\n",
    "        ciudad_prop = loc.get_text().split(\",\")[-1].strip()\n",
    "        precio = p.get_text(strip=True)\n",
    "        link = \"https://www.infocasas.com.uy\" + link_tag['href']"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aqui realizamos el filtrado y almacenamiento por ciudad (límite de 10)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "        # Agregar solo si es una de las ciudades que buscamos y no llegamos a 10\n",
    "        if ciudad_prop in ciudades_objetivo and len(resultado[ciudad_prop]) < 10:\n",
    "            resultado[ciudad_prop].append({\n",
    "                \"ciudad\": ciudad_prop,\n",
    "                \"precio\": precio,\n",
    "                \"link\": link,\n",
    "            })\n",
    "\n",
    "    page += 1"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Guardamos en JSON"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 16,
   "source": [
    "\n",
    "# Guardar en JSON\n",
    "with open(\"data.json\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    json.dump(resultado, outfile, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
